{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Eng for Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import preprocessing, pipeline, metrics, model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 100\n",
    "sns.set_style(\"white\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">These files contain loan data for all loans issued through the time period stated, including the current loan status (current, late, fully paid, etc.) and latest payment information.\n",
    "\n",
    "So, the data presentes the final status of the loan when the data is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries\n",
    "- Categorical features are proceed.\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat table_a (2011) and table_b (2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 3357: unexpected end of data\n"
     ]
    }
   ],
   "source": [
    "a_df = pd.read_csv(\"LoanStats3a_securev1.csv\",engine=\"python\",error_bad_lines=False,header=1)\n",
    "b_df = pd.read_csv(\"LoanStats3b_securev1.csv\",engine=\"python\",error_bad_lines=False,header=1)\n",
    "a_df['table'] = 'a'\n",
    "b_df['table'] = 'b'\n",
    "full_concat_df = pd.concat([a_df, b_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features not selected if fully missing in table_a and table_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all missing val faetures in combined table_a and table_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_full_null_list = ['member_id',  'next_pymnt_d',  'annual_inc_joint',  'dti_joint',  'verification_status_joint', \n",
    "                           'open_acc_6m',  'open_act_il',  'open_il_12m',  'open_il_24m',  'mths_since_rcnt_il',  \n",
    "                           'total_bal_il',  'il_util',  'open_rv_12m',  'open_rv_24m',  'max_bal_bc',  'all_util',  'inq_fi',  \n",
    "                           'total_cu_tl',  'inq_last_12m',  'revol_bal_joint',  'sec_app_fico_range_low',  'sec_app_fico_range_high',  \n",
    "                           'sec_app_earliest_cr_line',  'sec_app_inq_last_6mths',  'sec_app_mort_acc',  'sec_app_open_acc',  'sec_app_revol_util', \n",
    "                           'sec_app_open_act_il',  'sec_app_num_rev_accts',  'sec_app_chargeoff_within_12_mths',  'sec_app_collections_12_mths_ex_med',  \n",
    "                           'sec_app_mths_since_last_major_derog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all missing val features in table_a, i.e. year 2011 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_full_null_list = ['tot_coll_amt',  'tot_cur_bal',  'total_rev_hi_lim',  'acc_open_past_24mths',  'avg_cur_bal',  'mo_sin_old_rev_tl_op',  \n",
    "                    'mo_sin_rcnt_rev_tl_op',  'mo_sin_rcnt_tl',  'mort_acc',  'num_accts_ever_120_pd',  'num_actv_bc_tl',  'num_actv_rev_tl',  \n",
    "                    'num_bc_sats',  'num_bc_tl',  'num_il_tl',  'num_op_rev_tl',  'num_rev_accts',  'num_rev_tl_bal_gt_0',  'num_sats',  'num_tl_30dpd', \n",
    "                    'num_tl_90g_dpd_24m',  'num_tl_op_past_12m',  'pct_tl_nvr_dlq',  'tot_hi_cred_lim',  'total_bal_ex_mort',  \n",
    "                    'total_bc_limit',  'total_il_high_credit_limit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all missing val feature in table_b, year 2013 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_full_null_list = ['revol_util']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__features left after remove all those columns above__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_selected_column_list  = list(set(full_concat_df.columns) - set(concat_full_null_list + a_full_null_list + b_full_null_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application info \n",
    "Those features are possibly required when applying for a loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_features = ['id','addr_state', 'annual_inc','annual_inc_joint','application_type', 'desc', 'dti', 'dti_joint', 'earliest_cr_line', \n",
    "'emp_title', 'emp_length', 'emp_title','fico_range_high', 'fico_range_low','home_ownership', 'loan_amnt', 'msa', \n",
    "'pub_rec_bankruptcies', 'pub_rec', 'purpose', 'tax_liens','term', 'title', 'verification_status',\n",
    "'verified_status_joint','zip_code', 'sec_app_fico_range_high' , 'sec_app_fico_range_low']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__filtering the features of all null vals__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_apply_features = list(set(concat_selected_column_list).intersection(set(application_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_apply_features = filtered_apply_features + ['issue_d','table']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__features info__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use code below to view the features's missing value info\n",
    "```python\n",
    "full_concat_df[filtered_apply_features].info()\n",
    "\n",
    "full_concat_df[filtered_apply_features].isnull().sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'desc' has the higheset num of missing vals 3726\n",
    "- 'emp_title' has 345 missing vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Values Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code before for feature sanity check, \n",
    "\n",
    "```python\n",
    "full_concat_df['pub_rec'].value_counts()\n",
    "sns.barplot(x='pub_rec', y = 'id', data=full_concat_df, hue='loan_status', estimator=np.ma.count)\n",
    "full_concat_df['fico_range_high'].value_counts()\n",
    "full_concat_df['fico_range_low'].value_counts()\n",
    "sns.scatterplot(x='fico_range_low', y='fico_range_high', data=full_concat_df,hue='loan_status')\n",
    "full_concat_df['loan_amnt'].value_counts()\n",
    "full_concat_df['annual_inc'].value_counts()\n",
    "full_concat_df['verification_status'].value_counts()\n",
    "full_concat_df['issue_d'].value_counts()\n",
    "full_concat_df['earliest_cr_line'].value_counts()\n",
    "full_concat_df['home_ownership'].value_counts()\n",
    "full_concat_df['title'].value_counts()\n",
    "full_concat_df['purpose'].value_counts()\n",
    "full_concat_df['dti'].value_counts()\n",
    "full_concat_df['term'].value_counts()\n",
    "full_concat_df['purpose'].value_counts()\n",
    "full_concat_df['application_type'].value_counts()\n",
    "full_concat_df['pub_rec_bankruptcies'].value_counts()\n",
    "full_concat_df['zip_code'].value_counts()\n",
    "full_concat_df['tax_liens'].value_counts()\n",
    "full_concat_df['emp_title'].value_counts()\n",
    "full_concat_df['desc'].value_counts()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initial check the values of each feature, \"purposeï¼Œ dti, term,  loan_amnt, pub_rec_bankruptcies, zip_code, tax_liens, emp_title\" are selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_selected_features = ['id', 'issue_d','purpose',  'dti',  'term',  'loan_amnt',  'annual_inc',  'pub_rec_bankruptcies',  \n",
    " 'zip_code',  'tax_liens', 'emp_length', 'emp_title' , 'verification_status', 'earliest_cr_line',  'home_ownership' ,'fico_range_low', 'fico_range_high']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation and Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'loan_income_ration' for ratio of loan amount to the annuual incomde provided by borrower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['loan_income_ratio'] = full_concat_df['loan_amnt'] / full_concat_df['annual_inc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"issue_d\" and \"earliest_cr_line\" features has no missing val and encoded to date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_vars = ['issue_d', 'earliest_cr_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime encode: issue_d\n",
      "datetime encode: earliest_cr_line\n"
     ]
    }
   ],
   "source": [
    "dt_encode_no_missing_vars = []\n",
    "for dt_no_missing_var in datetime_vars:\n",
    "    print(f\"datetime encode: {dt_no_missing_var}\")\n",
    "    y_m_encode_var = dt_no_missing_var + \"_Y-M\"\n",
    "    dt_encode_no_missing_vars.append(y_m_encode_var)\n",
    "    y_encode_var = dt_no_missing_var + \"_year\"\n",
    "    dt_encode_no_missing_vars.append(y_encode_var)\n",
    "    m_encode_var = dt_no_missing_var + \"_month\"\n",
    "    dt_encode_no_missing_vars.append(m_encode_var)\n",
    "    \n",
    "    full_concat_df[y_m_encode_var] = pd.to_datetime(full_concat_df[dt_no_missing_var], format=\"%b-%Y\")\n",
    "    full_concat_df[y_encode_var] = pd.to_datetime(full_concat_df[dt_no_missing_var], format=\"%b-%Y\").apply(lambda x:x.year)\n",
    "    full_concat_df[m_encode_var] = pd.to_datetime(full_concat_df[dt_no_missing_var], format=\"%b-%Y\").apply(lambda x:x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['issue_d_Y-M',\n",
       " 'issue_d_year',\n",
       " 'issue_d_month',\n",
       " 'earliest_cr_line_Y-M',\n",
       " 'earliest_cr_line_year',\n",
       " 'earliest_cr_line_month']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_encode_no_missing_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode Categorical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"purpose\" label encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['purpose'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding purpose\n",
      "Label-encoded feaures: purpose_le\n"
     ]
    }
   ],
   "source": [
    "LB_purpose = preprocessing.LabelEncoder()\n",
    "\n",
    "to_le_var = 'purpose'\n",
    "print (\"Label Encoding %s\" % (to_le_var))\n",
    "LE_var=to_le_var+'_le'\n",
    "full_concat_df[LE_var]=LB_purpose.fit_transform(full_concat_df[to_le_var])\n",
    "\n",
    "print (\"Label-encoded feaures: %s\" % (LE_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['car', 'credit_card', 'debt_consolidation', 'home_improvement',\n",
       "       'house', 'major_purchase', 'medical', 'moving', 'other',\n",
       "       'renewable_energy', 'small_business', 'vacation', 'wedding'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LB_purpose.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"term\" encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['term_encode'] = full_concat_df['term'].apply(lambda x: 0 if '36' in x else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zip_code: truncated zip_code to 'other' when count <20 (roughly estimate by check the value_counts plot. Could be fine-tuned later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_zipcode_list = full_concat_df['zip_code'].value_counts().index[full_concat_df['zip_code'].value_counts()<20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_rare_zipcode(val):\n",
    "    if val in other_zipcode_list:\n",
    "        return 'other'\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['zip_code_truncated'] = full_concat_df['zip_code'].apply(replace_rare_zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding zip_code_truncated\n",
      "Label-encoded feaures: zip_code_truncated_le\n"
     ]
    }
   ],
   "source": [
    "LB_zip = preprocessing.LabelEncoder()\n",
    "\n",
    "to_le_var = 'zip_code_truncated'\n",
    "print (\"Label Encoding %s\" % (to_le_var))\n",
    "LE_var=to_le_var+'_le'\n",
    "full_concat_df[LE_var]=LB_zip.fit_transform(full_concat_df[to_le_var])\n",
    "\n",
    "print (\"Label-encoded feaures: %s\" % (LE_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    3465\n",
       "84      88\n",
       "14      87\n",
       "11      76\n",
       "50      76\n",
       "      ... \n",
       "52      20\n",
       "2       20\n",
       "45      20\n",
       "88      20\n",
       "25      20\n",
       "Name: zip_code_truncated_le, Length: 95, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['zip_code_truncated_le'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"emp_title\" encoding, truncated emp_title by replacy others when count of that category is less than 10. This truncated number could be fine-tuned later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_emp_title_list = full_concat_df['emp_title'].value_counts().index[full_concat_df['emp_title'].value_counts()<10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_rare_emp_title(val):\n",
    "    if val in other_emp_title_list:\n",
    "        return 'other'\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['emp_title_truncated'] = full_concat_df['emp_title'].apply(replace_rare_emp_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                  5830\n",
       "Teacher                  86\n",
       "Manager                  52\n",
       "RN                       30\n",
       "Project Manager          27\n",
       "Engineer                 25\n",
       "Sales                    24\n",
       "Supervisor               22\n",
       "Registered Nurse         21\n",
       "Director                 16\n",
       "Accountant               15\n",
       "Executive Assistant      14\n",
       "manager                  12\n",
       "Account Manager          12\n",
       "General Manager          12\n",
       "Driver                   12\n",
       "Vice President           11\n",
       "mechanic                 10\n",
       "Executive Director       10\n",
       "Name: emp_title_truncated, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['emp_title_truncated'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding emp_title_truncated_impute\n",
      "Label-encoded feaures: emp_title_truncated_impute_le\n"
     ]
    }
   ],
   "source": [
    "full_concat_df['emp_title_truncated_impute'] = full_concat_df['emp_title_truncated'].fillna('Missing')\n",
    "LB_emp_title = preprocessing.LabelEncoder()\n",
    "\n",
    "to_le_var = 'emp_title_truncated_impute'\n",
    "print (\"Label Encoding %s\" % (to_le_var))\n",
    "LE_var=to_le_var+'_le'\n",
    "full_concat_df[LE_var]=LB_emp_title.fit_transform(full_concat_df[to_le_var])\n",
    "\n",
    "print (\"Label-encoded feaures: %s\" % (LE_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Employment length\" encoding, the missing value replaced by -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['emp_length'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['emp_length_impute'] = full_concat_df['emp_length'].fillna('-999')\n",
    "full_concat_df['emp_length_impute_num'] = full_concat_df['emp_length_impute'].str.extract(r\"([-+]?[0-9]+)\")\\\n",
    ".astype('float').astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"verification_status\" enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "full_concat_df['verification_status'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verfication_status_encode(val):\n",
    "    if val == 'Verified':\n",
    "        return 0\n",
    "    if val == 'Source Verified':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['verification_status_le'] = full_concat_df['verification_status'].apply(verfication_status_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"home_ownership\" encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['home_ownership'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RENT        3065\n",
       "MORTGAGE    2998\n",
       "OWN          523\n",
       "Name: home_ownership, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['home_ownership'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def home_ownership_encode(val):\n",
    "    if val == 'RENT':\n",
    "        return 0\n",
    "    if val == 'OWN':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['home_ownership_le'] = full_concat_df['home_ownership'].apply(home_ownership_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3065\n",
       "2    2998\n",
       "1     523\n",
       "Name: home_ownership_le, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['home_ownership_le'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"tax_liens\" encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['tax_liens'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6499\n",
       "1      54\n",
       "2      21\n",
       "3       8\n",
       "4       3\n",
       "8       1\n",
       "Name: tax_liens, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['tax_liens'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding tax_liens\n",
      "Label-encoded feaures: tax_liens_le\n"
     ]
    }
   ],
   "source": [
    "LB_tax = preprocessing.LabelEncoder()\n",
    "\n",
    "to_le_var = 'tax_liens'\n",
    "print (\"Label Encoding %s\" % (to_le_var))\n",
    "LE_var=to_le_var+'_le'\n",
    "full_concat_df[LE_var]=LB_tax.fit_transform(full_concat_df[to_le_var])\n",
    "\n",
    "print (\"Label-encoded feaures: %s\" % (LE_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6499\n",
       "1      54\n",
       "2      21\n",
       "3       8\n",
       "4       3\n",
       "5       1\n",
       "Name: tax_liens_le, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_concat_df['tax_liens_le'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output the feature vars after encoding to csv file for random forest model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df.to_csv(\"df_to_RF_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train set from table_a where has issue in 2011, and test set from table_b has issue 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check \n",
    "full_concat_df[full_concat_df['table']=='a'].issue_d_year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[full_concat_df['table']=='b'].issue_d_year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode loan_status as target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['target'] = full_concat_df['loan_status'].apply(lambda x: 1 if x == 'Charged Off' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_vars = ['tax_liens_le', 'home_ownership_le','verification_status_le','emp_length_impute_num', \n",
    "               'emp_title_truncated_impute_le','zip_code_truncated_le','term_encode', 'purpose_le']\n",
    "\n",
    "num_vars = ['pub_rec_bankruptcies','dti','loan_amnt', 'annual_inc' ,'loan_income_ratio','fico_range_low','fico_range_high']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_features = num_vars + encode_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(full_concat_df, vars=predict_features, hue='loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[predict_features].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(4684)\n",
    "\n",
    "#split into train and test to avoid overfitting\n",
    "train_df = full_concat_df[full_concat_df['table']=='a'] \n",
    "# train_df = full_concat_df\n",
    "X_train, y_train = train_df[predict_features], train_df['target']\n",
    "\n",
    "test_df = full_concat_df[full_concat_df['table']=='b'] \n",
    "X_test, y_test = test_df[predict_features], test_df['target']\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced',oob_score=True)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_validate(rf, X_test, y_test, scoring=['recall','f1','roc_auc'], cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "# build the model\n",
    "\n",
    "rf.fit(X_train,y_train)\n",
    "  \n",
    "#let's print OOB accuracy and confusion matrix\n",
    "print(\n",
    "\"OOB accuracy is\", \n",
    "rf.oob_score_, \n",
    "\"\\n\", \n",
    "\"OOB Confusion Matrix\", \n",
    "\"\\n\",\n",
    "pd.DataFrame(confusion_matrix(y_train, rf.oob_decision_function_[:,1].round(), labels=[0, 1]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize performance\n",
    "for k,v in scores.items():\n",
    "    print(f\" {k}: mean val {np.mean(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = rf.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(rf.feature_importances_, index=predict_features)\n",
    "feat_importances.sort_values().plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__\"tax_liens_le\", \"pub_rec_bankruptcies\", \"home_ownership_le\", \"verication_status_le\" less than 5% important score__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "forest = RandomForestClassifier(class_weight='balanced')\n",
    "param_grid = [\n",
    "{'n_estimators': [10, 25,50,100]}\n",
    "]\n",
    "\n",
    "grid_search_forest = GridSearchCV(forest, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search_forest.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_forest.best_params_, grid_search_forest.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_predict_features = [\n",
    " 'dti',\n",
    " 'loan_amnt',\n",
    " 'annual_inc',\n",
    " 'loan_income_ratio',\n",
    " 'emp_length_impute_num',\n",
    " 'emp_title_truncated_impute_le',\n",
    " 'zip_code_truncated_le',\n",
    " 'term_encode',\n",
    " 'purpose_le',\n",
    "'fico_range_low',\n",
    "'fico_range_high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test to avoid overfitting\n",
    "refined_train_df = full_concat_df[full_concat_df['table']=='a'] \n",
    "# train_df = full_concat_df\n",
    "X_train, y_train = refined_train_df[refined_predict_features], train_df['target']\n",
    "\n",
    "test_df = full_concat_df[full_concat_df['table']=='b'] \n",
    "X_test, y_test = test_df[refined_predict_features], test_df['target']\n",
    "\n",
    "refined_rf = RandomForestClassifier(n_estimators=100, class_weight='balanced_subsample',oob_score=True)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=2, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_validate(refined_rf, X_test, y_test, scoring=['recall','f1','roc_auc'], cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "# build the model\n",
    "\n",
    "refined_rf.fit(X_train,y_train)\n",
    "  \n",
    "#let's print OOB accuracy and confusion matrix\n",
    "print(\n",
    "\"OOB accuracy is\", \n",
    "refined_rf.oob_score_, \n",
    "\"\\n\", \n",
    "\"OOB Confusion Matrix\", \n",
    "\"\\n\",\n",
    "pd.DataFrame(confusion_matrix(y_train, refined_rf.oob_decision_function_[:,1].round(), labels=[0, 1]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize performance\n",
    "for k,v in scores.items():\n",
    "    print(f\" {k}: mean val {np.mean(v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = refined_rf.predict(X_test)\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances = pd.Series(refined_rf.feature_importances_, index=refined_predict_features)\n",
    "feat_importances.sort_values().plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# class_weight='balanced_subsample'\n",
    "forest = RandomForestClassifier(class_weight={0:1, 1:20})\n",
    "param_grid = [\n",
    "{'n_estimators': [10, 25,50,100,150,200]}\n",
    "]\n",
    "\n",
    "grid_search_forest = GridSearchCV(forest, param_grid, cv=5, scoring='f1')\n",
    "grid_search_forest.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_forest.best_params_, grid_search_forest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr curve and pr auc on an imbalanced dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# plot no skill and model precision-recall curves\n",
    "def plot_pr_curve(test_y, model_probs):\n",
    "    # calculate the no skill line as the proportion of the positive class\n",
    "    no_skill = len(test_y[test_y==1]) / len(test_y)\n",
    "    # plot the no skill precision-recall curve\n",
    "    pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    # plot model precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(test_y, model_probs)\n",
    "    pyplot.plot(recall, precision, marker='.', label='RF')\n",
    "    # axis labels\n",
    "    pyplot.xlabel('Recall')\n",
    "    pyplot.ylabel('Precision')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    " \n",
    "# generate 2 class dataset\n",
    "# X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)\n",
    "# # split into train/test sets with same class ratio\n",
    "# trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
    "# # no skill model, stratified random class predictions\n",
    "model = DummyClassifier(strategy='stratified')\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict_proba(X_test)\n",
    "naive_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, naive_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('No Skill PR AUC: %.3f' % auc_score)\n",
    "# fit a model\n",
    "\n",
    "yhat = refined_rf.predict_proba(X_test)\n",
    "model_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, model_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('RF PR AUC: %.3f' % auc_score)\n",
    "# plot precision-recall curves\n",
    "plot_pr_curve(y_test, model_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Counter(model_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.hist(model_probs, bins=100)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 (add more features )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More features will be added to improve the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_additional_features = ['bc_util', 'funded_amnt' ,'funded_amnt_inv' ,'grade','initial_list_status', 'inq_fi','installment', 'int_rate' ,'mo_sin_old_il_acct','mo_sin_old_rev_tl_op', \n",
    "'sub_grade','sec_app_mort_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if duplicates with the features selected for application time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(application_features).intersection(set(init_additional_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature exploration and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[init_additional_features].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of total current balance to high credit/credit limit for all bankcard accounts.\n",
    "full_concat_df['bc_util'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(full_concat_df[full_concat_df['table']=='a'].bc_util.isnull().sum())/full_concat_df.bc_util.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nearly all of the missing val in table_a, which make it difficult to use for predict table_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='loan_status',y='bc_util',data=full_concat_df, estimator=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='loan_status',y='bc_util',data=full_concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation with -999\n",
    "full_concat_df['bc_util_impute'] = full_concat_df['bc_util'].fillna(-999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__funded_amnt, The total amount committed to that loan at that point in time.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['funded_amnt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='loan_status',y='funded_amnt',data=full_concat_df, estimator=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='loan_status',y='funded_amnt',data=full_concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funded_amnt_inv,The total amount committed by investors for that loan at that point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['funded_amnt_inv'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='loan_status',y='funded_amnt_inv',data=full_concat_df, estimator=np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='funded_amnt_inv', y = 'funded_amnt', data=full_concat_df, hue='loan_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nearly linear btw 'funded_amnt_inv' and 'funded_amnt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(full_concat_df['funded_amnt_inv']/full_concat_df['funded_amnt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grade: LC assigned loan grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['grade'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='grade', y='id', estimator=np.ma.count,data=full_concat_df[full_concat_df['target']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='grade', y='id', hue='loan_status',estimator=np.ma.count,data=full_concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for fully paid: \n",
    "rank from high to low : B,C,A,D,E,F,G\n",
    "\n",
    "for Charged Off:\n",
    "rank as: C,D,B,E,A,F,G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to numerical\n",
    "# encode 'grade', A->0, B->1, C->2, D->3,E->4, F->5, G->6\n",
    "def grade_encode(val):\n",
    "    if val == 'A':\n",
    "        return 0\n",
    "    if val == 'B':\n",
    "        return 1\n",
    "    if val == 'C':\n",
    "        return 2\n",
    "    if val == 'D':\n",
    "        return 3\n",
    "    if val == 'E':\n",
    "        return 4\n",
    "    if val == 'F':\n",
    "        return 5\n",
    "    else: # 'G'\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['grade_encode'] = full_concat_df['grade'].apply(grade_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['grade_encode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__subgrade feature__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['sub_grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform to numerical\n",
    "def sub_grade_encode(val):\n",
    "    if val[0] == 'A':\n",
    "        return int(val[1]) - 1\n",
    "    if val[0] == 'B':\n",
    "        return int(val[1]) + 4\n",
    "    if val[0] == 'C':\n",
    "        return int(val[1]) + 9\n",
    "    if val[0] == 'D':\n",
    "        return int(val[1]) + 14\n",
    "    if val[0] == 'E':\n",
    "        return int(val[1]) + 19\n",
    "    if val[0] == 'F':\n",
    "        return int(val[1]) + 24\n",
    "    else: # 'G'\n",
    "        return int(val[1]) + 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['sub_grade_encode'] = full_concat_df['sub_grade'].apply(sub_grade_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['sub_grade_encode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grade and sub_grade are evaluated by LC when the application info of borrower are given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='sub_grade_encode', y = 'grade_encode',data=full_concat_df,hue='loan_status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__initial_list_status: The initial listing status of the loan. Possible values are W, F__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['initial_list_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='initial_list_status', y='id', estimator=np.ma.count,data=full_concat_df[full_concat_df['target']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='initial_list_status', y='id', estimator=np.ma.count,data=full_concat_df[full_concat_df['target']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to numerical f->0, w->1\n",
    "full_concat_df['initial_list_status_encode'] = full_concat_df['initial_list_status'].apply(lambda x: 0 if x=='f' else 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['initial_list_status_encode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__installment: The monthly payment owed by the borrower if the loan originates.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['installment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='loan_status', y='installment', estimator=np.mean,data=full_concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__int_rate: interst rate__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['int_rate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to numerical\n",
    "full_concat_df['int_rate_encode'] = full_concat_df['int_rate'].str.extract(r\"(\\d+\\.\\d+)\").astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['int_rate_encode'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='int_rate_encode', y = 'sub_grade_encode', data=full_concat_df, hue='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intesest correlates with sub_grade, and for different issue year, for same sub grade >5, later year has higher int rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mo_sin_old_il_acct\n",
    "\n",
    "full_concat_df[full_concat_df['table']=='a'].mo_sin_old_il_acct.isnull().sum()/full_concat_df['mo_sin_old_il_acct'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nearly all missing val from table a, cannot use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mo_sin_old_rev_tl_op\n",
    "full_concat_df[full_concat_df['table']=='a'].mo_sin_old_rev_tl_op.isnull().sum()/full_concat_df['mo_sin_old_rev_tl_op'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all missing val from table a, cannot use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summaries\n",
    "- features not selected: bc_util,mo_sin_old_il_acct, mo_sin_old_rev_tl_op, inq_fi, mo_sin_old_rev_tl_op\n",
    "- features selected: funded_amnt_inv, funded_amnt_inv, grade_encode,sub_grade_encode, initial_list_status_encode, installment, int_rate_encode, \n",
    "- observation: \n",
    "    - funded_amnt_inv, funded_amnt_inv: nearly linear \n",
    "    - int_rate differs from issue year of 2011(lower) and 2013(higher)\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_selected_feature_round2 = ['funded_amnt', 'funded_amnt_inv', 'grade_encode','sub_grade_encode', 'initial_list_status_encode', 'installment', 'int_rate_encode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round2_features = refined_predict_features +add_selected_feature_round2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round2_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test to avoid overfitting\n",
    "train_df = full_concat_df[full_concat_df['table']=='a'] \n",
    "# train_df = full_concat_df\n",
    "# X_train, y_train = train_df[round2_features], train_df['target']\n",
    "\n",
    "# test_df = full_concat_df[full_concat_df['table']=='b'] \n",
    "# X_test, y_test = test_df[round2_features], test_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df[round2_features], train_df['target'], stratify=train_df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "round2_rf = RandomForestClassifier(n_estimators=100, criterion='gini',class_weight='balanced',oob_score=True)\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_validate(round2_rf, X_test, y_test, scoring=['recall','f1','roc_auc'], cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "# build the model\n",
    "\n",
    "round2_rf.fit(X_train,y_train)\n",
    "  \n",
    "#let's print OOB accuracy and confusion matrix\n",
    "print(\n",
    "\"OOB accuracy is\", \n",
    "refined_rf.oob_score_, \n",
    "\"\\n\", \n",
    "\"OOB Confusion Matrix\", \n",
    "\"\\n\",\n",
    "pd.DataFrame(confusion_matrix(y_train, round2_rf.oob_decision_function_[:,1].round(), labels=[0, 1]))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# summarize performance\n",
    "for k,v in scores.items():\n",
    "    print(f\" {k}: mean val {np.mean(v)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_predict = round2_rf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "\n",
    "\n",
    "feat_importances = pd.Series(round2_rf.feature_importances_, index=round2_features)\n",
    "feat_importances.sort_values().plot(kind='barh')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr curve and pr auc on an imbalanced dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# plot no skill and model precision-recall curves\n",
    "def plot_pr_curve(test_y, model_probs):\n",
    "    # calculate the no skill line as the proportion of the positive class\n",
    "    no_skill = len(test_y[test_y==1]) / len(test_y)\n",
    "    # plot the no skill precision-recall curve\n",
    "    pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    # plot model precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(test_y, model_probs)\n",
    "    pyplot.plot(recall, precision, marker='.', label='RF')\n",
    "    # axis labels\n",
    "    pyplot.xlabel('Recall')\n",
    "    pyplot.ylabel('Precision')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    " \n",
    "# generate 2 class dataset\n",
    "# X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)\n",
    "# # split into train/test sets with same class ratio\n",
    "# trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
    "# # no skill model, stratified random class predictions\n",
    "model = DummyClassifier(strategy='stratified')\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict_proba(X_test)\n",
    "naive_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, naive_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('No Skill PR AUC: %.3f' % auc_score)\n",
    "# fit a model\n",
    "\n",
    "yhat = round2_rf.predict_proba(X_test)\n",
    "model_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, model_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('RF PR AUC: %.3f' % auc_score)\n",
    "# plot precision-recall curves\n",
    "plot_pr_curve(y_test, model_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permutation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(round2_rf, X_train, y_train, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2,scoring='f1')\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_train.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (train set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### more progressive features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__percent_bc_gt_75ï¼š Percentage of all bankcard accounts > 75% of limit.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['percent_bc_gt_75'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[full_concat_df['table']=='a'].percent_bc_gt_75.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lot of missing in table a, but could show if good feature in table b alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='loan_status', y ='percent_bc_gt_75', data=full_concat_df[full_concat_df['table']=='b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__delinq_2yrsï¼šThe number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It imapct the recent 2 year history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['delinq_2yrs'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['delinq_2yrs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='loan_status', y ='delinq_2yrs', estimator=np.mean, data=full_concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__delinq_amntï¼š The past-due amount owed for the accounts on which the borrower is now delinquent.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['delinq_amnt'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['delinq_amnt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='loan_status', y ='delinq_amnt', data=full_concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a good predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__inq_last_12m: Number of credit inquiries in past 12 month__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['inq_last_12m'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__inq_last_6mths The number of inquiries in past 6 months (excluding auto and mortgage inquiries)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['inq_last_6mths'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['inq_last_6mths'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='loan_status', y ='inq_last_6mths', data=full_concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='loan_status', y ='inq_last_6mths', estimator=np.mean, data=full_concat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__mort_acc: Number of mortgage accounts__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mort_acc\n",
    "full_concat_df['mort_acc'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[full_concat_df['table']=='a'].mort_acc.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mort_acc mssing in table a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['mort_acc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x='loan_status', y ='mort_acc', data=full_concat_df[full_concat_df['table']=='b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='loan_status', y ='mort_acc', estimator=np.mean, data=full_concat_df[full_concat_df['table']=='b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "possible to use for table b predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__mths_since_last_delinq: The number of months since the borrower's last delinquency.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['mths_since_last_delinq'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[full_concat_df['table']=='a'].mths_since_last_delinq.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nearly 70% missing value, and in both table a and table b, hard to be selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__mths_since_last_major_derog Months since most recent 90-day or worse rating__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['mths_since_last_major_derog'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "too many missing val, and cannot find its null meaning on the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__mths_since_recent_bc_dlq: Months since most recent bankcard delinquency__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_concat_df['mths_since_recent_bc_dlq'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "too many missing val, and cannot find its null meaning on the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__num_tl_120dpd_2m: Number of accounts currently 120 days past due (updated in past 2 months)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_concat_df['num_tl_120dpd_2m'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[full_concat_df['table']=='a'].num_tl_120dpd_2m.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nearly of missing vals in table a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__num_tl_30dpd: Number of accounts currently 30 days past due (updated in past 2 months)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['num_tl_30dpd'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[full_concat_df['table']=='a'].num_tl_30dpd.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nearly of missing vals in table a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__num_tl_90g_dpd_24m:Number of accounts 90 or more days past due in last 24 months__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['num_tl_90g_dpd_24m'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[full_concat_df['table']=='a'].num_tl_90g_dpd_24m.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nearly of missing vals in table a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__num_tl_op_past_12m__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df['num_tl_op_past_12m'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[full_concat_df['table']=='a'].num_tl_op_past_12m.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nearly of missing vals in table a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__missing vals:__\n",
    "\n",
    "- inq_last_12m: Number of credit inquiries in past 12 month: missing all in table a and table b\n",
    "- percent_bc_gt_75ï¼š Percentage of all bankcard accounts > 75% of limit.__: missing all in table a\n",
    "- mort_acc: Number of mortgage accounts, missing all in table a\n",
    "- mths_since_last_delinq: The number of months since the borrower's last delinquency.nearly 70% missing value, and in both table a and table b, hard to be selected\n",
    "- mths_since_recent_bc_dlq: Months since most recent bankcard delinquency. too many missing val, and cannot find its null meaning on the website\n",
    "- num_tl_120dpd_2m: Number of accounts currently 120 days past due (updated in past 2 months),nearly of missing vals in table a\n",
    "- num_tl_30dpd: Number of accounts currently 30 days past due (updated in past 2 months), nearly of missing vals in table a\n",
    "- num_tl_90g_dpd_24m:Number of accounts 90 or more days past due in last 24 months, nearly of missing vals in table a\n",
    "- num_tl_op_past_12m: nearly of missing vals in table a\n",
    "\n",
    "__selected__:\n",
    "\n",
    "- delinq_2yrsï¼šThe number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n",
    "- delinq_amntï¼š The past-due amount owed for the accounts on which the borrower is now delinquent.\n",
    "- inq_last_6mths The number of inquiries in past 6 months (excluding auto and mortgage inquiries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_progressive_features = ['delinq_2yrs', 'delinq_amnt', 'inq_last_6mths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[progressive_features].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progressive_features = add_progressive_features + round2_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test to avoid overfitting\n",
    "train_df = full_concat_df[full_concat_df['table']=='a'] \n",
    "# train_df = full_concat_df\n",
    "# X_train, y_train = train_df[round2_features], train_df['target']\n",
    "\n",
    "# test_df = full_concat_df[full_concat_df['table']=='b'] \n",
    "# X_test, y_test = test_df[round2_features], test_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df[progressive_features], train_df['target'], stratify=train_df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "progress_rf = RandomForestClassifier(n_estimators=100, criterion='gini',class_weight='balanced',oob_score=True)\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_validate(progress_rf, X_test, y_test, scoring=['recall','f1','roc_auc'], cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "# build the model\n",
    "\n",
    "progress_rf.fit(X_train,y_train)\n",
    "  \n",
    "#let's print OOB accuracy and confusion matrix\n",
    "print(\n",
    "\"OOB accuracy is\", \n",
    "refined_rf.oob_score_, \n",
    "\"\\n\", \n",
    "\"OOB Confusion Matrix\", \n",
    "\"\\n\",\n",
    "pd.DataFrame(confusion_matrix(y_train, progress_rf.oob_decision_function_[:,1].round(), labels=[0, 1]))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# summarize performance\n",
    "for k,v in scores.items():\n",
    "    print(f\" {k}: mean val {np.mean(v)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_predict = progress_rf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "\n",
    "\n",
    "feat_importances = pd.Series(progress_rf.feature_importances_, index=progressive_features)\n",
    "feat_importances.sort_values().plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr curve and pr auc on an imbalanced dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# plot no skill and model precision-recall curves\n",
    "def plot_pr_curve(test_y, model_probs):\n",
    "    # calculate the no skill line as the proportion of the positive class\n",
    "    no_skill = len(test_y[test_y==1]) / len(test_y)\n",
    "    # plot the no skill precision-recall curve\n",
    "    pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    # plot model precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(test_y, model_probs)\n",
    "    pyplot.plot(recall, precision, marker='.', label='RF')\n",
    "    # axis labels\n",
    "    pyplot.xlabel('Recall')\n",
    "    pyplot.ylabel('Precision')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    " \n",
    "# generate 2 class dataset\n",
    "# X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)\n",
    "# # split into train/test sets with same class ratio\n",
    "# trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
    "# # no skill model, stratified random class predictions\n",
    "model = DummyClassifier(strategy='stratified')\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict_proba(X_test)\n",
    "naive_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, naive_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('No Skill PR AUC: %.3f' % auc_score)\n",
    "# fit a model\n",
    "\n",
    "yhat = progress_rf.predict_proba(X_test)\n",
    "model_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, model_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('RF PR AUC: %.3f' % auc_score)\n",
    "# plot precision-recall curves\n",
    "plot_pr_curve(y_test, model_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(progress_rf, X_train, y_train, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2,scoring='f1')\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_train.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (train set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible leak features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- last_pymnt_amnt: Last total payment amount received\n",
    "- total_rec_prncp: Principal received to date\n",
    "- last_fico_range_high: The upper boundary range the borrower??s last FICO pulled belongs to.\n",
    "- last_fico_range_low, The lower boundary range the borrower??s last FICO pulled belongs to.\n",
    "- total pymant: Payments received to date for total amount funded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'total_rec_prncp', 'last_pymnt_amnt', 'total_pymnt'\n",
    "add_leak_features = ['last_fico_range_high','last_fico_range_low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_leak_featres = add_leak_features + progressive_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test to avoid overfitting\n",
    "train_df = full_concat_df[full_concat_df['table']=='a'] \n",
    "# train_df = full_concat_df\n",
    "# X_train, y_train = train_df[round2_features], train_df['target']\n",
    "\n",
    "# test_df = full_concat_df[full_concat_df['table']=='b'] \n",
    "# X_test, y_test = test_df[round2_features], test_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df[possible_leak_featres], train_df['target'], stratify=train_df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "possible_leak_rf = RandomForestClassifier(n_estimators=100, criterion='gini',class_weight='balanced',oob_score=True)\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_validate(possible_leak_rf, X_test, y_test, scoring=['recall','f1','roc_auc'], cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "# build the model\n",
    "\n",
    "possible_leak_rf.fit(X_train,y_train)\n",
    "  \n",
    "#let's print OOB accuracy and confusion matrix\n",
    "print(\n",
    "\"OOB accuracy is\", \n",
    "refined_rf.oob_score_, \n",
    "\"\\n\", \n",
    "\"OOB Confusion Matrix\", \n",
    "\"\\n\",\n",
    "pd.DataFrame(confusion_matrix(y_train, possible_leak_rf.oob_decision_function_[:,1].round(), labels=[0, 1]))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# summarize performance\n",
    "for k,v in scores.items():\n",
    "    print(f\" {k}: mean val {np.mean(v)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_predict = possible_leak_rf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "\n",
    "\n",
    "feat_importances = pd.Series(possible_leak_rf.feature_importances_, index=possible_leak_featres)\n",
    "feat_importances.sort_values().plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr curve and pr auc on an imbalanced dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# plot no skill and model precision-recall curves\n",
    "def plot_pr_curve(test_y, model_probs):\n",
    "    # calculate the no skill line as the proportion of the positive class\n",
    "    no_skill = len(test_y[test_y==1]) / len(test_y)\n",
    "    # plot the no skill precision-recall curve\n",
    "    pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    # plot model precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(test_y, model_probs)\n",
    "    pyplot.plot(recall, precision, marker='.', label='RF')\n",
    "    # axis labels\n",
    "    pyplot.xlabel('Recall')\n",
    "    pyplot.ylabel('Precision')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    " \n",
    "# generate 2 class dataset\n",
    "# X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)\n",
    "# # split into train/test sets with same class ratio\n",
    "# trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
    "# # no skill model, stratified random class predictions\n",
    "model = DummyClassifier(strategy='stratified')\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict_proba(X_test)\n",
    "naive_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, naive_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('No Skill PR AUC: %.3f' % auc_score)\n",
    "# fit a model\n",
    "\n",
    "yhat = possible_leak_rf.predict_proba(X_test)\n",
    "model_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, model_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('RF PR AUC: %.3f' % auc_score)\n",
    "# plot precision-recall curves\n",
    "plot_pr_curve(y_test, model_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(possible_leak_rf, X_train, y_train, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2,scoring='f1')\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(result.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_train.columns[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (train set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traing only 2013 data with features missied in 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_2011_missied_features = ['percent_bc_gt_75', 'mort_acc', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_concat_df[all_2011_missied_features].loc[full_concat_df['table']=='b'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df = full_concat_df[full_concat_df['table']=='b'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df['issue_d_year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df['num_tl_90g_dpd_24m'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df['percent_bc_gt_75'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation\n",
    "b_df['percent_bc_gt_75_impute'] = b_df['percent_bc_gt_75'].fillna(value=-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_2011_missied_features = ['percent_bc_gt_75_impute', 'mort_acc', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2013_featres = all_2011_missied_features + progressive_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_df[train_2013_featres].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test to avoid overfitting\n",
    "train_df =b_df\n",
    "# train_df = full_concat_df\n",
    "# X_train, y_train = train_df[round2_features], train_df['target']\n",
    "\n",
    "# test_df = full_concat_df[full_concat_df['table']=='b'] \n",
    "# X_test, y_test = test_df[round2_features], test_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df[train_2013_featres], train_df['target'], stratify=train_df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "train2013_rf = RandomForestClassifier(n_estimators=100, criterion='gini',class_weight='balanced',oob_score=True)\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=2, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_validate(train2013_rf, X_test, y_test, scoring=['recall','f1','roc_auc'], cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "# build the model\n",
    "\n",
    "train2013_rf.fit(X_train,y_train)\n",
    "  \n",
    "#let's print OOB accuracy and confusion matrix\n",
    "print(\n",
    "\"OOB accuracy is\", \n",
    "refined_rf.oob_score_, \n",
    "\"\\n\", \n",
    "\"OOB Confusion Matrix\", \n",
    "\"\\n\",\n",
    "pd.DataFrame(confusion_matrix(y_train, train2013_rf.oob_decision_function_[:,1].round(), labels=[0, 1]))\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# summarize performance\n",
    "for k,v in scores.items():\n",
    "    print(f\" {k}: mean val {np.mean(v)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_predict = train2013_rf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_predict))\n",
    "\n",
    "\n",
    "feat_importances = pd.Series(train2013_rf.feature_importances_, index=train_2013_featres)\n",
    "feat_importances.sort_values().plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr curve and pr auc on an imbalanced dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# plot no skill and model precision-recall curves\n",
    "def plot_pr_curve(test_y, model_probs):\n",
    "    # calculate the no skill line as the proportion of the positive class\n",
    "    no_skill = len(test_y[test_y==1]) / len(test_y)\n",
    "    # plot the no skill precision-recall curve\n",
    "    pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    # plot model precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(test_y, model_probs)\n",
    "    pyplot.plot(recall, precision, marker='.', label='RF')\n",
    "    # axis labels\n",
    "    pyplot.xlabel('Recall')\n",
    "    pyplot.ylabel('Precision')\n",
    "    # show the legend\n",
    "    pyplot.legend()\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    " \n",
    "# generate 2 class dataset\n",
    "# X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.99, 0.01], random_state=1)\n",
    "# # split into train/test sets with same class ratio\n",
    "# trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=2, stratify=y)\n",
    "# # no skill model, stratified random class predictions\n",
    "model = DummyClassifier(strategy='stratified')\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict_proba(X_test)\n",
    "naive_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, naive_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('No Skill PR AUC: %.3f' % auc_score)\n",
    "# fit a model\n",
    "\n",
    "yhat = train2013_rf.predict_proba(X_test)\n",
    "model_probs = yhat[:, 1]\n",
    "# calculate the precision-recall auc\n",
    "precision, recall, _ = precision_recall_curve(y_test, model_probs)\n",
    "auc_score = auc(recall, precision)\n",
    "print('RF PR AUC: %.3f' % auc_score)\n",
    "# plot precision-recall curves\n",
    "plot_pr_curve(y_test, model_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
